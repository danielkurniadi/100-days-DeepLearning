{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron, MNIST\n",
    "---\n",
    "In this notebook, we will train an MLP to classify images from the [MNIST database](http://yann.lecun.com/exdb/mnist/) hand-written digit database.\n",
    "\n",
    "The process will be broken down into the following steps:\n",
    ">1. Load and visualize the data\n",
    "2. Define a neural network\n",
    "3. Train the model\n",
    "4. Evaluate the performance of our trained model on a test dataset!\n",
    "\n",
    "Before we begin, we have to import the necessary libraries for working with data and PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load and Visualize the [Data](http://pytorch.org/docs/stable/torchvision/datasets.html)\n",
    "\n",
    "Downloading may take a few moments, and you should see your progress as the data is loading. You may also choose to change the `batch_size` if you want to load more data at a time.\n",
    "\n",
    "This cell will create DataLoaders for each of our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# define transform Object\n",
    "transform = transform.ToTensor() # convert data to torch.FloatTensor\n",
    "\n",
    "# download pytorch MNIST training and test set\n",
    "train_data = datasets.MNIST(root='data/', train=True, # using MNIST/processed/training.pt\n",
    "                           download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data/', train=False, # using MNIST/processed/test.pt\n",
    "                          download=True, transform=transform)\n",
    "\n",
    "# prepare data loader\n",
    "train_loader = None\n",
    "test_ loader = None\n",
    "\n",
    "# specify the image classes\n",
    "classes = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "           'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize a Batch of Training Data\n",
    "\n",
    "The first step in a classification task is to take a look at the data, make sure it is loaded in correctly, then make any initial observations about patterns in that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as pt\n",
    "%matplotlib inline\n",
    "\n",
    "dataiter = iter(train_loader) # get iterator for train_loader object\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "# plot the figure of MNIST images in a batch, along with corresponding labels\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "\n",
    "for idx, image in enumerate(images):\n",
    "    # make figure of 4x5\n",
    "    ax = fig.add_subplot(4, 5, idx+1, xticks=[], yticks=[])\n",
    "    ax.imshow(image.squeeze())\n",
    "    ax.set_title(str(labels[idx].item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images.numpy().squeeze()[12] # pick any from 0-19\n",
    "width, height = img.shape\n",
    "\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.imshow(img)\n",
    "\n",
    "thresh_color = img.max()/2\n",
    "for i in range(width):\n",
    "    for j in range(height):\n",
    "        val = round(img[i][j], 2) if (img[i][j] < 0.01) else 0\n",
    "        ax.annotate(str(val), xy=(j,i),\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    color='white' if img[i][j]<thresh else 'black')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Define the Network [Architecture](http://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "The architecture will be responsible for seeing as input a 784-dim Tensor of pixel values for each image, and producing a Tensor of length 10 (our number of classes) that indicates the class scores for an input image. This particular example uses two hidden layers and dropout to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers_sizes, num_classes=10, drop_p=0.5):\n",
    "        \"\"\"Initialise a network of fully connected/MLP layers with specification\n",
    "        Arguments:\n",
    "            ______________________\n",
    "            - input_size: (int or tuple) size/dimension of input matrix per img.\n",
    "            - hidden_layers_sizes: (list) channel lengths of linear layers.\n",
    "            - num_classes: (int) number of classes to classify.\n",
    "            - drop_p: (float; 0<=p<=1) dropout layer probability.\n",
    "        \"\"\"\n",
    "        super(MLPNet, self).__init__()\n",
    "        # Determine initial input size\n",
    "        if isinstance(input_size, int):\n",
    "            self.input_size = int(input_size)\n",
    "        elif isinstance(input_size, (list,tuple)):\n",
    "            self.input_size = np.prod(input_size)\n",
    "        else:\n",
    "            raise Exception(f\"Input size: {input_size} expect integer or tuple to specify dimension.\")\n",
    "        \n",
    "        #TODO: add hidden layers\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\" Feed forward raw input to models\n",
    "        Arguments\n",
    "            ______________________\n",
    "            input: Vectors or Matrices of input data\n",
    "        \"\"\"\n",
    "        # flatten input if not done so.\n",
    "        \n",
    "        # forward flow\n",
    "        \n",
    "        return None\n",
    "\n",
    "model = MLPNet(img.shape, [48, 32, 20, 16], num_classes=10, drop_p=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Specify [Loss Function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [Optimizer](http://pytorch.org/docs/stable/optim.html)\n",
    "\n",
    "It's recommended that you use cross-entropy loss for classification. If you look at the documentation (linked above), you can see that PyTorch's cross entropy function applies a softmax funtion to the output layer *and* then calculates the log loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Network\n",
    "The steps for training/learning from a batch of data are described in the comments below:\n",
    "\n",
    "1. Clear the gradients of all optimized variables\n",
    "2. Forward pass: compute predicted outputs by passing inputs to the model\n",
    "3. Calculate the loss\n",
    "4. Backward pass: compute gradient of the loss with respect to model parameters\n",
    "5. Perform a single optimization step (parameter update)\n",
    "6. Update average training loss\n",
    "\n",
    "The following loop trains for 50 epochs; take a look at how the values for the training loss decrease over time. We want it to decrease while also avoiding overfitting the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 1\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data, target in train_loader:\n",
    "        ###\n",
    "        train_loss += loss.item() * data.size(0)\n",
    "    \n",
    "    # print train_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###  Defining [Network Architecture](http://pytorch.org/docs/stable/nn.html)\n",
    "We will be using an Convolutional Neural Network. We will use the following architecture:\n",
    "* [Convolutional layers](https://pytorch.org/docs/stable/nn.html#conv2d), which can be thought of as stack of filtered images.\n",
    "* [Maxpooling layers](https://pytorch.org/docs/stable/nn.html#maxpool2d), which reduce the size of the input matrix, which only keeps the most active pixels from prev layer.\n",
    "* The usual Linear + Dropout layers to avoid overfitting and produce a 10-dim output.\n",
    "A network with 2 convolutional layers is shown in the image below and in the code, and you've been given starter code with one convolutional and one maxpooling layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Trained Network\n",
    "Finally, we test our best model on previously unseen test data and evaluate it's performance. Testing on unseen data is a good way to check that our model generalizes well. It may also be useful to be granular in this analysis and take a look at how this model performs on each class as well as looking at its overall loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Sample Test Results\n",
    "This cell displays test images and their labels in this format: predicted (ground-truth). The text will be green for accurately classified examples and red for incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udacity-dl",
   "language": "python",
   "name": "udacity-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
